{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Machine Learning Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotten Tomatoes Classifier\n",
    "#### Rotten Tomatoes is a popular website for movie ratings. They provide an audience score where anybody can review the movie. They also have a critic score. These scores are calculated by looking at the percentage of people that gave the movie a positive rating. For example, if a movie has 90 positive critic reviews, 10 negative critic reviews, 60 positive audience reviews, and 40 negative audience reviews then the critic score would be 0.9 and the audience score would be 0.6. If a movie has a critic score above 0.6 then it is classified as \"fresh\". Our goal is to predict whether a movie will get a fresh critic score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "* Name: name of the movie\n",
    "* Audience Score: Rotten Tomatoes audience score\n",
    "* Audience Ratings: Number of audience reviewers contributing to the score\n",
    "* Budget: budget for the movie\n",
    "* Box Office: Domestic earnings + International earnings from the movie\n",
    "* Genre: One of (action, thriller, horror, animation, adventure, musical, comedy)\n",
    "* Rating: One of (PG, PG-13, R)\n",
    "* Is Fresh: What we are trying to predict\n",
    "\n",
    "#### Training Data Table:\n",
    "\n",
    "| Name                                    | audience_score | audience_ratings | budget | box_office | genre     | rating | is_fresh? |\n",
    "|-----------------------------------------|----------------|------------------|--------|------------|-----------|--------|-----------|\n",
    "| Jurassic World : Fallen Kingdom         | 0.49           | 29,091           | 170M   | 1.309B     | action    | PG-13  | no        |\n",
    "| Venom                                   | 0.81           | 38,684           | 100M   | 856M       | action    | PG-13  | no        |\n",
    "| Fantastic Beasts: Crimes of Grindelwald | 0.56           | 14,038           | 200M   | 653M       | adventure | PG-13  | no        |\n",
    "| The Meg                                 | 0.46           | 6,344            | 130M   | 530M       | thriller  | PG-13  | no        |\n",
    "| The Nun                                 | 0.36           | 6,506            | 22M    | 365M       | horror    | R      | no        |\n",
    "| Black Panther                           | 0.76           | 88,211           | 200M   | 1.346B     | action    | PG-13  | yes       |\n",
    "| Incredibles 2                           | 0.85           | 17,343           | 200M   | 1.242B     | animation | PG     | yes       |\n",
    "| Bohemian Rhapsody                       | 0.86           | 21,731           | 52M    | 903M       | drama     | PG-13  | yes       |\n",
    "| A Star is Born                          | 0.80           | 18,862           | 36M    | 434M       | drama     | R      | yes       |\n",
    "| A Quiet Place                           | 0.83           | 21,439           | 17M    | 340M       | horror    | PG-13  | yes       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading In Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    y = data['is_fresh'].values.tolist()\n",
    "    x = data.drop(['is_fresh'], axis=1)\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y) = get_data(\"movie_train.csv\") # loading data from csv file\n",
    "train_rows = len(train_x) # getting number of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.head(3) # print out first 3 entries in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[0:3] # print out first 3 labels for training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Index into Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the 3rd row of data:\n",
    "i = 2 # remember that python starts counting at 0\n",
    "row_i = train_x.iloc[i]\n",
    "print(\"Row i:\")\n",
    "print(row_i)\n",
    "print(\"******\")\n",
    "# Getting name and audience score for row_i\n",
    "print(\"Audience score for %s is %s\" % (row_i['name'], row_i['audience_score']))\n",
    "print(\"******\")\n",
    "# One line for above\n",
    "print(\"Audience score for %s is %s\" % (train_x.iloc[i]['name'], train_x.iloc[i]['audience_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Performance Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "predicted_is_fresh : array of size n with predictions\n",
    "actual_is_fresh : array of size n with actual values\n",
    "returns: accuracy score from 0 to 1\n",
    "\"\"\"\n",
    "def get_accuracy(predicted_is_fresh, actual_is_fresh):\n",
    "    if (len(predicted_is_fresh) != len(actual_is_fresh)):\n",
    "        return \"invalid_inputs\"\n",
    "    total_entries = 1.0*len(predicted_is_fresh)\n",
    "    total_correct = 0\n",
    "    for i in range(len(predicted_is_fresh)):\n",
    "        if predicted_is_fresh[i] == actual_is_fresh[i]:\n",
    "            total_correct += 1\n",
    "    return total_correct/total_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_positive_rate(predicted_is_fresh, actual_is_fresh):\n",
    "    if (len(predicted_is_fresh) != len(actual_is_fresh)):\n",
    "        return \"invalid_inputs\"\n",
    "    total_positive = 0\n",
    "    total_correct_positive = 0\n",
    "    for i in range(len(predicted_is_fresh)):\n",
    "        if actual_is_fresh[i] == \"yes\":\n",
    "            total_positive += 1\n",
    "            if predicted_is_fresh[i] == actual_is_fresh[i]:\n",
    "                total_correct_positive += 1\n",
    "    return 1.0*total_correct_positive/total_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_negative_rate(predicted_is_fresh, actual_is_fresh):\n",
    "    # TODO\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: We want to test the functions above, what should go into the accuracy variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test for function above\n",
    "predicted_is_fresh = ['yes','yes','yes','no']\n",
    "actual_is_fresh = ['yes','yes','no','no']\n",
    "accuracy = 0 # TODO: What should this be?\n",
    "assert(get_accuracy(predicted_is_fresh, actual_is_fresh) == accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positve_rate = 1\n",
    "assert(get_true_positive_rate(predicted_is_fresh, actual_is_fresh) == true_positve_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative_rate = 0.5\n",
    "assert(get_true_negative_rate(predicted_is_fresh, actual_is_fresh) == true_negative_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Classification Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Make this better\n",
    "def classify_row(row):\n",
    "    if (row['rating'] == 'PG-13'):\n",
    "        return \"no\"\n",
    "    else:\n",
    "        return \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_all_data(data):\n",
    "    predictions = []\n",
    "    for i in range(len(data)):\n",
    "        predictions.append(classify_row(data.iloc[i]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = classify_all_data(train_x)\n",
    "print(\"predictions:  \" + str(predictions_train))\n",
    "print(\"actual values:\" + str(train_y))\n",
    "accuracy_train = get_accuracy(predictions_train,train_y)\n",
    "print(\"Training Accuracy: %0.2f\" % accuracy_train)\n",
    "true_positive_rate_train = get_true_positive_rate(predictions_train,train_y)\n",
    "print(\"True Positive Rate: %0.2f\" % true_positive_rate_train)\n",
    "true_negative_rate_train = get_true_negative_rate(predictions_train,train_y)\n",
    "print(\"True Negative Rate: %0.2f\" % true_negative_rate_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Lets See Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_x, test_y) = get_data(\"movie_test.csv\") # loading data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = classify_all_data(test_x)\n",
    "print(\"Testing Accuracy: %0.2f\" % get_accuracy(predictions_test,test_y))\n",
    "print(\"Testing True Positive Rate: %0.2f\" % get_true_positive_rate(predictions_test,test_y))\n",
    "print(\"Testing True Negative Rate: %0.2f\" % get_true_negative_rate(predictions_test,test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
